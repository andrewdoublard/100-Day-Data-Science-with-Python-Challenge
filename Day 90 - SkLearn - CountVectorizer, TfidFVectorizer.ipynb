{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96efabee",
   "metadata": {},
   "source": [
    "## Exercise 1:\n",
    "#### The following list with text documents is given:\n",
    "\n",
    "documents = [\n",
    "    'python is a programming language',\n",
    "    'python is popular',\n",
    "    'programming in python',\n",
    "    'object-oriented programming in python'\n",
    "]\n",
    "\n",
    "\n",
    "#### Vectorize your documents with the CountVectorizer class from the scikit-learn. Use the stop_words argument and set its value to 'english'.\n",
    "\n",
    "#### In response, print the result as a DataFrame object as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3b60924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language  object  oriented  popular  programming  python\n",
      "0         1       0         0        0            1       1\n",
      "1         0       0         0        1            0       1\n",
      "2         0       0         0        0            1       1\n",
      "3         0       1         1        0            1       1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "documents = [\n",
    "    'python is a programming language',\n",
    "    'python is popular',\n",
    "    'programming in python',\n",
    "    'object-oriented programming in python'\n",
    "]\n",
    "\n",
    "cr = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=cr.fit_transform(documents).toarray(),\n",
    "    columns=cr.get_feature_names_out(),\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550cdb3",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "#### The following list with text documents is given:\n",
    "\n",
    "#### Vectorize your documents with the CountVectorizer class from the scikit-learn. Use the stop_words argument and set its value to 'english'. Also set the appropriate argument that allows you to extract n-grams: unigrams and bigrams.\n",
    "\n",
    "#### In response, print result as a DataFrame object as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46385c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   language  object  object oriented  oriented  oriented programming  popular  programming  programming language  programming python  python  python popular  python programming\n",
      "0         1       0                0         0                     0        0            1                     1                   0       1               0                   1\n",
      "1         0       0                0         0                     0        1            0                     0                   0       1               1                   0\n",
      "2         0       0                0         0                     0        0            1                     0                   1       1               0                   0\n",
      "3         0       1                1         1                     1        0            1                     0                   1       1               0                   0\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "\n",
    "cr = CountVectorizer(stop_words = 'english', ngram_range = (1,2))\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=cr.fit_transform(documents).toarray(),\n",
    "    columns=cr.get_feature_names_out(),\n",
    ")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b5d6cd",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "#### Vectorize the given documents using the TfidfVectorizer class from the scikit-learn.\n",
    "\n",
    "#### In response, print result as a DataFrame object as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab17180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         in        is  language    object  oriented   popular  programming    python\n",
      "0  0.000000  0.519714  0.659191  0.000000  0.000000  0.000000     0.420753  0.343993\n",
      "1  0.000000  0.572892  0.000000  0.000000  0.000000  0.726641     0.000000  0.379192\n",
      "2  0.691131  0.000000  0.000000  0.000000  0.000000  0.000000     0.559530  0.457453\n",
      "3  0.433919  0.000000  0.000000  0.550372  0.550372  0.000000     0.351295  0.287207\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data = tvec.fit_transform(documents).toarray(),\n",
    "    columns = tvec.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9afdaa",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "- Use Cases: CountVectorizer() is simpler and works well for bag-of-words models or when word frequency is important, while TfidfVectorizer() is better for scenarios where it's important to minimize the influence of common words and emphasize unique or less frequent terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb086a",
   "metadata": {},
   "source": [
    "## Exercise 4:\n",
    "#### Load the clusters.csv file into the DataFrame and assign to df variable. The distribution of the variables form this file is as follows:\n",
    "#### Using the AgglomerativeClustering class from the scikit-learn, create a model to split given dataset into two clusters. Make a prediction based on this model and assign a new column 'cluster' which stores the cluster number for each sample in the df DataFrame.\n",
    "\n",
    "#### In response, print the first ten rows of the df DataFrame to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a591d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2  cluster\n",
      "0 -2.486532  7.025770        0\n",
      "1 -3.522549  8.578303        0\n",
      "2 -2.982040  7.998514        0\n",
      "3 -2.135276  6.255888        0\n",
      "4  2.762504  4.210918        1\n",
      "5 -3.541472  8.489106        0\n",
      "6  1.240259  0.781640        1\n",
      "7  0.053390  8.966770        0\n",
      "8 -0.827918  6.742253        0\n",
      "9  3.291716  1.296751        1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "df = pd.read_csv('clusters.csv')\n",
    "\n",
    "ac = AgglomerativeClustering(n_clusters = 2)\n",
    "\n",
    "df['cluster'] = ac.fit_predict(X = df)\n",
    "\n",
    "print(df.head(10))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
